{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Word2Vec_transformation_with_gensim & Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wyc_0lfv98xf",
        "colab_type": "text"
      },
      "source": [
        "# The data\n",
        "\n",
        "   ##  About the data\n",
        "The analysis seeks to establish transformation of word into vectors on any text. We are not concerned about whether the text data has label or not. The data set supplied consists of  **50000 IMDB reviews**  with review ID on a certain movie  with no labels.We'll use this unlabelled data to train a model. which can be applied on test data.\n",
        "\n",
        "Please visit the site to download the data\n",
        "https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qjeipfq-Xvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUO7x4uTqEyv",
        "colab_type": "text"
      },
      "source": [
        "## Import the data\n",
        "\n",
        "The data was imported from local repository using the command below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6nYK0Zs-ePR",
        "colab_type": "code",
        "outputId": "51fa2e4c-cf71-479c-9442-b075f335c221",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58ba0203-4553-4589-b937-2c36dcf1cfbf\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-58ba0203-4553-4589-b937-2c36dcf1cfbf\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving unlabeledTrainData.tsv to unlabeledTrainData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb2PtvNs-ezJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"unlabeledTrainData.tsv\",delimiter=\"\\t\",quoting=3,header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beTir5Bc-e13",
        "colab_type": "code",
        "outputId": "cd7d8176-cb49-4a03-b97c-1baf43b42a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                             review\n",
              "0   \"9999_0\"  \"Watching Time Chasers, it obvious that it was...\n",
              "1  \"45057_0\"  \"I saw this film about 20 years ago and rememb...\n",
              "2  \"15561_0\"  \"Minor Spoilers<br /><br />In New York, Joan B...\n",
              "3   \"7161_0\"  \"I went to see this film with a great deal of ...\n",
              "4  \"43971_0\"  \"Yes, I agree with everyone on this site this ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCGqHLWu-e7m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re,string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEa71UBQe9X7",
        "colab_type": "text"
      },
      "source": [
        "##  Data Cleaning\n",
        "We've gone through the reviews & detected punctuations in many reviews.The punctuations don't contribute anything to our analysis & moreover they are considered as unique word & distort the meaning of other words.This is why the data needs to be cleaned before we jump into core analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWxkM_PZ-e-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_string(string):                                                         # The entire document is cleaned defining clean_string\n",
        "  try:\n",
        "    string=re.sub(r'^https?:\\/\\/<>.*[\\r\\n]*','',string,flags=re.MULTILINE)\n",
        "    string=re.sub(r\"[^A-Za-z]\",\" \",string)\n",
        "    words=string.strip().lower().split()\n",
        "    return \" \".join(words)\n",
        "  except:\n",
        "    return \" \"\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRrc9brjJyEP",
        "colab_type": "text"
      },
      "source": [
        "Above we defined a function called **clean_string** & this function we have applied on the raw review column and created a new column(**clean_review**) to save the cleaned reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rZpIB7i-fBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['clean_review']=df.review.apply(clean_string)                                  # Finally cleaned format is applied on the reviews\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrIOSWx3-fFk",
        "colab_type": "code",
        "outputId": "2f61bf32-8d90-4dbe-c94a-2cb1204b1320",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "print (\"No.of samples \\n:\",(len(df)))\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.of samples \n",
            ": 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"9999_0\"</td>\n",
              "      <td>\"Watching Time Chasers, it obvious that it was...</td>\n",
              "      <td>watching time chasers it obvious that it was m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"45057_0\"</td>\n",
              "      <td>\"I saw this film about 20 years ago and rememb...</td>\n",
              "      <td>i saw this film about years ago and remember i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"15561_0\"</td>\n",
              "      <td>\"Minor Spoilers&lt;br /&gt;&lt;br /&gt;In New York, Joan B...</td>\n",
              "      <td>minor spoilers br br in new york joan barnard ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"7161_0\"</td>\n",
              "      <td>\"I went to see this film with a great deal of ...</td>\n",
              "      <td>i went to see this film with a great deal of e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"43971_0\"</td>\n",
              "      <td>\"Yes, I agree with everyone on this site this ...</td>\n",
              "      <td>yes i agree with everyone on this site this mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  ...                                       clean_review\n",
              "0   \"9999_0\"  ...  watching time chasers it obvious that it was m...\n",
              "1  \"45057_0\"  ...  i saw this film about years ago and remember i...\n",
              "2  \"15561_0\"  ...  minor spoilers br br in new york joan barnard ...\n",
              "3   \"7161_0\"  ...  i went to see this film with a great deal of e...\n",
              "4  \"43971_0\"  ...  yes i agree with everyone on this site this mo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEWVMOiItP2L",
        "colab_type": "text"
      },
      "source": [
        "If we look at the data now, we'll not notice any punctuations in the **clean_review** column."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcKWqrLo2ZRz",
        "colab_type": "text"
      },
      "source": [
        "#  Word2Vec with Gensim(The Word2Vec toolkit)\n",
        "\n",
        "Gensim is an open source Python library for natural language processing, with a focus on topic modeling.Gensim was developed and is maintained by the Czech natural language processing researcher **Radim Řehůřek** and his company RaRe Technologies.\n",
        "\n",
        "It is not an everything-including-the-kitchen-sink NLP research library (like NLTK); instead, Gensim is a mature, focused, and efficient suite of NLP tools for topic modeling. Most notably for this tutorial, it supports an implementation of the** Word2Vec word embedding** for learning new word vectors from text.\n",
        "\n",
        "It also provides tools for loading pre-trained word embeddings in a few formats and for making use and querying a loaded embedding.\n",
        "\n",
        "\n",
        "### Objective\n",
        "\n",
        "In this tutorial, we dig a little \"deeper\" into sentiment analysis. Google's Word2Vec is a deep-learning inspired method that focuses on the meaning of words. Word2Vec attempts to understand meaning and **semantic relationships** among words. It works in a way that is similar to deep approaches, such as recurrent neural nets or deep neural nets, but is computationally more efficient. This tutorial focuses on Word2Vec for sentiment analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4OuxlUSuPy7",
        "colab_type": "text"
      },
      "source": [
        "**Please install & import the gensim everytime you work on Google colab**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK0rq-GZ-e45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gensim --quiet                                      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16M51r6GOuFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgGRlg9MuehZ",
        "colab_type": "text"
      },
      "source": [
        "**Since we are going to work with words, so we are required to split the each review so that we can have word tokens.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtVP0tOb-fJL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Document=[]\n",
        "for doc in df['clean_review']:\n",
        "  Document.append(doc.split(' '))                             "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tta5zrdnrlft",
        "colab_type": "code",
        "outputId": "132c1226-bd8a-4b7f-ba51-5d828c799e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(Document)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfp2mtdQu8oU",
        "colab_type": "text"
      },
      "source": [
        "**Let us explore split reviews**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV4hRqzwVt4V",
        "colab_type": "code",
        "outputId": "fd8c4cd9-d606-4e41-e41e-7e2622fe9d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Document[10][6:13]                                                                # This what is there in 10th Document starting from 6 till 12"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['movie', 'i', 'am', 'not', 'sure', 'whether', 'i']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQWDFXrYVt7G",
        "colab_type": "code",
        "outputId": "1066d7dc-3b56-4b6d-c083-fcba4c30cdfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "print(len(Document[10]))                                                          # Lenth of the 10th document ,  It has 524 words in it\n",
        "print(Document[10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "524\n",
            "['after', 'reading', 'the', 'comments', 'for', 'this', 'movie', 'i', 'am', 'not', 'sure', 'whether', 'i', 'should', 'be', 'angry', 'sad', 'or', 'sickened', 'seeing', 'comments', 'typical', 'of', 'people', 'who', 'a', 'know', 'absolutely', 'nothing', 'about', 'the', 'military', 'or', 'b', 'who', 'base', 'everything', 'they', 'think', 'they', 'know', 'on', 'movies', 'like', 'this', 'or', 'on', 'cnn', 'reports', 'about', 'abu', 'gharib', 'makes', 'me', 'wonder', 'about', 'the', 'state', 'of', 'intellectual', 'stimulation', 'in', 'the', 'world', 'br', 'br', 'at', 'the', 'time', 'i', 'type', 'this', 'the', 'number', 'of', 'people', 'in', 'the', 'us', 'military', 'million', 'on', 'active', 'duty', 'with', 'another', 'almost', 'in', 'the', 'guard', 'and', 'reserves', 'for', 'a', 'total', 'of', 'roughly', 'million', 'br', 'br', 'the', 'number', 'of', 'people', 'indicted', 'for', 'abuses', 'at', 'at', 'abu', 'gharib', 'currently', 'less', 'than', 'br', 'br', 'that', 'makes', 'the', 'total', 'of', 'people', 'indicted', 'of', 'the', 'total', 'military', 'even', 'if', 'you', 'indict', 'every', 'single', 'military', 'member', 'that', 'ever', 'stepped', 'in', 'to', 'abu', 'gharib', 'you', 'would', 'not', 'come', 'close', 'to', 'making', 'that', 'a', 'whole', 'number', 'br', 'br', 'the', 'flaws', 'in', 'this', 'movie', 'would', 'take', 'years', 'to', 'cover', 'i', 'understand', 'that', 'it', 's', 'supposed', 'to', 'be', 'sarcastic', 'but', 'in', 'reality', 'the', 'writer', 'and', 'director', 'are', 'trying', 'to', 'make', 'commentary', 'about', 'the', 'state', 'of', 'the', 'military', 'without', 'an', 'enemy', 'to', 'fight', 'in', 'reality', 'the', 'us', 'military', 'has', 'been', 'at', 'its', 'busiest', 'when', 'there', 'are', 'not', 'conflicts', 'going', 'on', 'the', 'military', 'is', 'the', 'first', 'called', 'for', 'disaster', 'relief', 'and', 'humanitarian', 'aid', 'missions', 'when', 'the', 'tsunami', 'hit', 'indonesia', 'devestating', 'the', 'region', 'the', 'us', 'military', 'was', 'the', 'first', 'on', 'the', 'scene', 'when', 'the', 'chaos', 'of', 'the', 'situation', 'overwhelmed', 'the', 'local', 'governments', 'it', 'was', 'military', 'leadership', 'who', 'looked', 'at', 'their', 'people', 'the', 'same', 'people', 'this', 'movie', 'mocks', 'and', 'said', 'make', 'it', 'happen', 'within', 'hours', 'food', 'aid', 'was', 'reaching', 'isolated', 'villages', 'within', 'days', 'airfields', 'were', 'built', 'cargo', 'aircraft', 'started', 'landing', 'and', 'a', 'food', 'distribution', 'system', 'was', 'up', 'and', 'running', 'hours', 'and', 'days', 'not', 'weeks', 'and', 'months', 'yes', 'there', 'are', 'unscrupulous', 'people', 'in', 'the', 'us', 'military', 'but', 'then', 'there', 'are', 'in', 'every', 'walk', 'of', 'life', 'every', 'occupation', 'but', 'to', 'see', 'people', 'on', 'this', 'website', 'decide', 'that', 'million', 'men', 'and', 'women', 'are', 'all', 'criminal', 'with', 'nothing', 'on', 'their', 'minds', 'but', 'thoughts', 'of', 'destruction', 'or', 'mayhem', 'is', 'an', 'absolute', 'disservice', 'to', 'the', 'things', 'that', 'they', 'do', 'every', 'day', 'one', 'person', 'on', 'this', 'website', 'even', 'went', 'so', 'far', 'as', 'to', 'say', 'that', 'military', 'members', 'are', 'in', 'it', 'for', 'personal', 'gain', 'wow', 'entry', 'level', 'personnel', 'make', 'just', 'under', 'an', 'hour', 'assuming', 'a', 'hour', 'work', 'week', 'of', 'course', 'many', 'work', 'much', 'more', 'than', 'hours', 'a', 'week', 'and', 'those', 'in', 'harm', 's', 'way', 'typically', 'put', 'in', 'hour', 'days', 'for', 'months', 'on', 'end', 'that', 'makes', 'the', 'pay', 'well', 'under', 'minimum', 'wage', 'so', 'much', 'for', 'personal', 'gain', 'i', 'beg', 'you', 'please', 'make', 'yourself', 'familiar', 'with', 'the', 'world', 'around', 'you', 'go', 'to', 'a', 'nearby', 'base', 'get', 'a', 'visitor', 'pass', 'and', 'meet', 'some', 'of', 'the', 'men', 'and', 'women', 'you', 'are', 'so', 'quick', 'to', 'disparage', 'you', 'would', 'be', 'surprised', 'the', 'military', 'no', 'longer', 'accepts', 'people', 'in', 'lieu', 'of', 'prison', 'time', 'they', 'require', 'a', 'minimum', 'of', 'a', 'ged', 'and', 'prefer', 'a', 'high', 'school', 'diploma', 'the', 'middle', 'ranks', 'are', 'expected', 'to', 'get', 'a', 'minimum', 'of', 'undergraduate', 'degrees', 'and', 'the', 'upper', 'ranks', 'are', 'encouraged', 'to', 'get', 'advanced', 'degrees']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jamR9vRCPJM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging                                                                    # Please import logging to keep & check information regarding word2vec transformation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fdKWAs2VuAX",
        "colab_type": "code",
        "outputId": "98b57a5b-3a9f-41aa-cddb-1409ac53ca14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "\n",
        "model=gensim.models.Word2Vec(Document,                                           # List of reviews\n",
        "                          min_count=10,                                          # we want words appearing atleast 10 times in the vocab otherwise ignore \n",
        "                          workers=4,                                             # Use these many worker threads to train the model (=faster training with multicore machines\n",
        "                           size=50,                                              # it means aword is represented by 50 numbers,in other words the number of neorons in hidden layer is 50 \n",
        "                          window=5)                                              # 5 neighbors on the either side of a word"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-30 04:49:08,789 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
            "2019-06-30 04:49:08,792 : INFO : collecting all words and their counts\n",
            "2019-06-30 04:49:08,793 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2019-06-30 04:49:09,279 : INFO : PROGRESS: at sentence #10000, processed 2399440 words, keeping 51654 word types\n",
            "2019-06-30 04:49:09,749 : INFO : PROGRESS: at sentence #20000, processed 4835846 words, keeping 69077 word types\n",
            "2019-06-30 04:49:10,225 : INFO : PROGRESS: at sentence #30000, processed 7267977 words, keeping 81515 word types\n",
            "2019-06-30 04:49:10,707 : INFO : PROGRESS: at sentence #40000, processed 9669772 words, keeping 91685 word types\n",
            "2019-06-30 04:49:11,172 : INFO : collected 100479 word types from a corpus of 12084660 raw words and 50000 sentences\n",
            "2019-06-30 04:49:11,173 : INFO : Loading a fresh vocabulary\n",
            "2019-06-30 04:49:11,640 : INFO : effective_min_count=10 retains 28322 unique words (28% of original 100479, drops 72157)\n",
            "2019-06-30 04:49:11,641 : INFO : effective_min_count=10 leaves 11910457 word corpus (98% of original 12084660, drops 174203)\n",
            "2019-06-30 04:49:11,727 : INFO : deleting the raw counts dictionary of 100479 items\n",
            "2019-06-30 04:49:11,731 : INFO : sample=0.001 downsamples 49 most-common words\n",
            "2019-06-30 04:49:11,732 : INFO : downsampling leaves estimated 8817283 word corpus (74.0% of prior 11910457)\n",
            "2019-06-30 04:49:11,831 : INFO : estimated required memory for 28322 words and 50 dimensions: 25489800 bytes\n",
            "2019-06-30 04:49:11,832 : INFO : resetting layer weights\n",
            "2019-06-30 04:49:12,057 : INFO : training model with 4 workers on 28322 vocabulary and 50 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
            "2019-06-30 04:49:13,083 : INFO : EPOCH 1 - PROGRESS: at 7.27% examples, 626042 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:14,103 : INFO : EPOCH 1 - PROGRESS: at 14.71% examples, 629862 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:15,103 : INFO : EPOCH 1 - PROGRESS: at 22.31% examples, 641345 words/s, in_qsize 8, out_qsize 0\n",
            "2019-06-30 04:49:16,113 : INFO : EPOCH 1 - PROGRESS: at 29.31% examples, 635584 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:17,122 : INFO : EPOCH 1 - PROGRESS: at 36.47% examples, 633777 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:18,126 : INFO : EPOCH 1 - PROGRESS: at 43.48% examples, 632315 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:19,135 : INFO : EPOCH 1 - PROGRESS: at 50.74% examples, 633370 words/s, in_qsize 8, out_qsize 0\n",
            "2019-06-30 04:49:20,155 : INFO : EPOCH 1 - PROGRESS: at 57.88% examples, 631693 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-30 04:49:21,161 : INFO : EPOCH 1 - PROGRESS: at 65.32% examples, 635163 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:22,191 : INFO : EPOCH 1 - PROGRESS: at 72.75% examples, 634255 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:23,198 : INFO : EPOCH 1 - PROGRESS: at 80.30% examples, 636017 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:24,198 : INFO : EPOCH 1 - PROGRESS: at 87.45% examples, 635108 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:25,204 : INFO : EPOCH 1 - PROGRESS: at 94.75% examples, 635989 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:25,859 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-30 04:49:25,869 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-30 04:49:25,881 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-30 04:49:25,882 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-30 04:49:25,883 : INFO : EPOCH - 1 : training on 12084660 raw words (8817845 effective words) took 13.8s, 638054 effective words/s\n",
            "2019-06-30 04:49:26,922 : INFO : EPOCH 2 - PROGRESS: at 7.43% examples, 632727 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:49:27,936 : INFO : EPOCH 2 - PROGRESS: at 14.87% examples, 634925 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:28,950 : INFO : EPOCH 2 - PROGRESS: at 22.48% examples, 641897 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:29,958 : INFO : EPOCH 2 - PROGRESS: at 30.15% examples, 650335 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:30,961 : INFO : EPOCH 2 - PROGRESS: at 37.69% examples, 654292 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:31,967 : INFO : EPOCH 2 - PROGRESS: at 45.29% examples, 657952 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:32,970 : INFO : EPOCH 2 - PROGRESS: at 52.96% examples, 660051 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:33,986 : INFO : EPOCH 2 - PROGRESS: at 60.60% examples, 661684 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:35,009 : INFO : EPOCH 2 - PROGRESS: at 67.82% examples, 657297 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:36,017 : INFO : EPOCH 2 - PROGRESS: at 75.51% examples, 658380 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:37,023 : INFO : EPOCH 2 - PROGRESS: at 83.26% examples, 659978 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:38,026 : INFO : EPOCH 2 - PROGRESS: at 90.60% examples, 658047 words/s, in_qsize 7, out_qsize 1\n",
            "2019-06-30 04:49:39,043 : INFO : EPOCH 2 - PROGRESS: at 98.33% examples, 659286 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:39,259 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-30 04:49:39,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-30 04:49:39,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-30 04:49:39,287 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-30 04:49:39,288 : INFO : EPOCH - 2 : training on 12084660 raw words (8817046 effective words) took 13.4s, 658103 effective words/s\n",
            "2019-06-30 04:49:40,296 : INFO : EPOCH 3 - PROGRESS: at 7.19% examples, 629564 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:41,299 : INFO : EPOCH 3 - PROGRESS: at 14.79% examples, 644038 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:42,299 : INFO : EPOCH 3 - PROGRESS: at 22.31% examples, 648678 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:43,303 : INFO : EPOCH 3 - PROGRESS: at 29.48% examples, 645586 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:44,316 : INFO : EPOCH 3 - PROGRESS: at 36.73% examples, 642164 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:45,332 : INFO : EPOCH 3 - PROGRESS: at 43.96% examples, 641875 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:46,353 : INFO : EPOCH 3 - PROGRESS: at 51.46% examples, 643565 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:47,359 : INFO : EPOCH 3 - PROGRESS: at 58.74% examples, 643562 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-30 04:49:48,405 : INFO : EPOCH 3 - PROGRESS: at 65.65% examples, 637362 words/s, in_qsize 5, out_qsize 2\n",
            "2019-06-30 04:49:49,406 : INFO : EPOCH 3 - PROGRESS: at 73.24% examples, 639490 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:50,430 : INFO : EPOCH 3 - PROGRESS: at 80.71% examples, 639169 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:51,434 : INFO : EPOCH 3 - PROGRESS: at 88.23% examples, 640689 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:52,445 : INFO : EPOCH 3 - PROGRESS: at 95.47% examples, 640337 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:53,000 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-30 04:49:53,007 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-30 04:49:53,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-30 04:49:53,022 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-30 04:49:53,023 : INFO : EPOCH - 3 : training on 12084660 raw words (8817211 effective words) took 13.7s, 642257 effective words/s\n",
            "2019-06-30 04:49:54,051 : INFO : EPOCH 4 - PROGRESS: at 7.43% examples, 638478 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:55,056 : INFO : EPOCH 4 - PROGRESS: at 14.95% examples, 644596 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:56,068 : INFO : EPOCH 4 - PROGRESS: at 22.31% examples, 641387 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:57,073 : INFO : EPOCH 4 - PROGRESS: at 29.73% examples, 645317 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:49:58,084 : INFO : EPOCH 4 - PROGRESS: at 36.99% examples, 643608 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:49:59,100 : INFO : EPOCH 4 - PROGRESS: at 43.80% examples, 636194 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:50:00,119 : INFO : EPOCH 4 - PROGRESS: at 51.15% examples, 636798 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:01,139 : INFO : EPOCH 4 - PROGRESS: at 58.58% examples, 638262 words/s, in_qsize 8, out_qsize 1\n",
            "2019-06-30 04:50:02,148 : INFO : EPOCH 4 - PROGRESS: at 65.82% examples, 638439 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:03,158 : INFO : EPOCH 4 - PROGRESS: at 73.32% examples, 639165 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:04,176 : INFO : EPOCH 4 - PROGRESS: at 80.79% examples, 639214 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:05,181 : INFO : EPOCH 4 - PROGRESS: at 88.23% examples, 640131 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:06,195 : INFO : EPOCH 4 - PROGRESS: at 95.47% examples, 639667 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:06,765 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-30 04:50:06,775 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-30 04:50:06,778 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-30 04:50:06,784 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-30 04:50:06,785 : INFO : EPOCH - 4 : training on 12084660 raw words (8817485 effective words) took 13.8s, 641013 effective words/s\n",
            "2019-06-30 04:50:07,792 : INFO : EPOCH 5 - PROGRESS: at 7.34% examples, 643043 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:08,806 : INFO : EPOCH 5 - PROGRESS: at 14.64% examples, 632847 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:09,811 : INFO : EPOCH 5 - PROGRESS: at 21.21% examples, 614135 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:10,823 : INFO : EPOCH 5 - PROGRESS: at 28.38% examples, 616409 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:50:11,842 : INFO : EPOCH 5 - PROGRESS: at 35.89% examples, 623915 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:50:12,871 : INFO : EPOCH 5 - PROGRESS: at 43.06% examples, 624217 words/s, in_qsize 5, out_qsize 2\n",
            "2019-06-30 04:50:13,872 : INFO : EPOCH 5 - PROGRESS: at 50.58% examples, 630131 words/s, in_qsize 7, out_qsize 1\n",
            "2019-06-30 04:50:14,878 : INFO : EPOCH 5 - PROGRESS: at 57.97% examples, 632580 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:15,888 : INFO : EPOCH 5 - PROGRESS: at 65.00% examples, 631798 words/s, in_qsize 8, out_qsize 0\n",
            "2019-06-30 04:50:16,892 : INFO : EPOCH 5 - PROGRESS: at 72.41% examples, 632835 words/s, in_qsize 6, out_qsize 1\n",
            "2019-06-30 04:50:17,895 : INFO : EPOCH 5 - PROGRESS: at 79.66% examples, 632387 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:18,898 : INFO : EPOCH 5 - PROGRESS: at 86.78% examples, 631532 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:19,926 : INFO : EPOCH 5 - PROGRESS: at 94.17% examples, 632171 words/s, in_qsize 7, out_qsize 0\n",
            "2019-06-30 04:50:20,765 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
            "2019-06-30 04:50:20,767 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
            "2019-06-30 04:50:20,770 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
            "2019-06-30 04:50:20,771 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
            "2019-06-30 04:50:20,773 : INFO : EPOCH - 5 : training on 12084660 raw words (8815738 effective words) took 14.0s, 630384 effective words/s\n",
            "2019-06-30 04:50:20,774 : INFO : training on a 60423300 raw words (44085325 effective words) took 68.7s, 641560 effective words/s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHlVJEoXC5PD",
        "colab_type": "text"
      },
      "source": [
        "**Please note that after applying Word2Vec function on the clean_review giving all the arguments corretly we have got 28322 words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RYnV85LCq3r",
        "colab_type": "code",
        "outputId": "f8d584f2-70d2-4e33-c8ad-4f34ffaa1911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(model.wv.vocab))                                                        # Now the vocab contains 28322 uinque words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdk_HDQWD0ct",
        "colab_type": "text"
      },
      "source": [
        "**Let's check the dimension of a vector i.e. the number of words that represent a word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DGahs80Dv6J",
        "colab_type": "code",
        "outputId": "e17712cc-6e94-489e-b7b8-405667d4f2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(model.wv.vector_size)                                                       # It means each vector has 50 numbers in it or in other words each word is vector of 5o numbers that we predefined"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqmrT73MQsgm",
        "colab_type": "code",
        "outputId": "72cab4c2-9174-4ca8-8393-5be08013a2ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.wv.vectors.shape                                                            # Dimension of the the entire corpus        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28322, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhGHd2OREPSz",
        "colab_type": "text"
      },
      "source": [
        "### Let's explore some interesting results of word2vec experiment\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db44U_SoVuC6",
        "colab_type": "code",
        "outputId": "159f7e23-4330-490b-91fd-8fb5c91e013d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "model.wv.most_similar(\"beautiful\")                                                # 10 similar words beautiful,the maximum similarity is 1,minimum is 0.When they are completely similar the \n",
        "                                                                                  # Value will be 1 , when completely dissimilar,the value will be 0."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-30 04:50:32,822 : INFO : precomputing L2-norms of word weight vectors\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gorgeous', 0.8662823438644409),\n",
              " ('lovely', 0.8383572101593018),\n",
              " ('stunning', 0.8253401517868042),\n",
              " ('wonderful', 0.7457817196846008),\n",
              " ('haunting', 0.7313393354415894),\n",
              " ('breathtaking', 0.7230619788169861),\n",
              " ('delicious', 0.7071415781974792),\n",
              " ('delightful', 0.6918222904205322),\n",
              " ('exquisite', 0.6858062148094177),\n",
              " ('fabulous', 0.6851967573165894)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NbHKeQg6kP9",
        "colab_type": "code",
        "outputId": "2edbcde9-5732-4cf4-cc79-9e6f73a2ac15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "model.wv.most_similar(\"princess\")                                                  # 10 similar words returned with numbers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('widow', 0.8457926511764526),\n",
              " ('prince', 0.8364083170890808),\n",
              " ('maid', 0.8170045614242554),\n",
              " ('nurse', 0.8026759028434753),\n",
              " ('queen', 0.7945679426193237),\n",
              " ('dakota', 0.7875654101371765),\n",
              " ('alice', 0.7805353403091431),\n",
              " ('pianist', 0.7736424207687378),\n",
              " ('maria', 0.7730264067649841),\n",
              " ('servant', 0.7711195945739746)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-tDNwJD-fQs",
        "colab_type": "code",
        "outputId": "bb35a0ac-9a19-4582-f5a7-88901cd598c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "model.wv.doesnt_match(\"she talked to me in the evening publicly\".split())         # publicly does not match in the sentence given"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'publicly'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3lClNUZFpQE",
        "colab_type": "text"
      },
      "source": [
        "Below the word **right** is represented by a dense 50 dimensional vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sj-zNbJ6kKo",
        "colab_type": "code",
        "outputId": "2e7f8089-4079-4721-e883-9309ee107d1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.wv[\"right\"]                                                                  # right word is represented by 50 numbers in other words the word \"right\" is vector of 50 numbers\n",
        "                                                                                   # 50 numbers are summarized weights because these numbers are obtained in the hidden layer of predefined 50 neurons"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.084792  ,  0.9277433 ,  1.2515309 ,  1.1081741 , -1.0420096 ,\n",
              "        1.9343015 ,  1.6928643 ,  1.3139058 , -0.55044943,  1.7915639 ,\n",
              "        1.3197316 , -0.64483315,  0.45559508,  0.80886555, -2.484303  ,\n",
              "        0.17833237,  1.3680307 ,  1.3672882 , -2.1542923 , -0.12052315,\n",
              "       -0.02813105,  0.3288807 ,  3.7106562 ,  0.13608542, -0.5899354 ,\n",
              "       -0.06722905, -2.050071  , -1.3693739 ,  0.18830606,  1.7286797 ,\n",
              "       -1.0732532 , -0.8536867 ,  1.1823726 ,  1.9744762 ,  0.42149726,\n",
              "        0.8830604 , -0.06469347,  2.1468382 , -1.2366889 , -2.5028865 ,\n",
              "       -2.1869085 ,  0.43791404, -0.16663122, -1.2541647 , -2.5873227 ,\n",
              "        2.2192307 ,  0.88265616, -1.2270586 , -0.9617601 , -0.36817485],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnENAcilu0pP",
        "colab_type": "code",
        "outputId": "96529568-a98a-4952-8aad-39691b0bd751",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "model.wv['great']"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.6426506 ,  0.05484062, -1.2672698 ,  0.0847162 ,  5.371844  ,\n",
              "        2.1987514 ,  1.7663705 ,  0.5578455 ,  1.0657201 ,  5.6036015 ,\n",
              "       -0.23015527, -2.7573566 ,  0.13810502, -0.2886024 , -2.2121024 ,\n",
              "        0.6800541 ,  1.4409364 ,  1.2620891 , -0.64830357,  1.0953355 ,\n",
              "        1.7287182 ,  2.8370798 ,  2.4627166 ,  0.42812717,  0.3164176 ,\n",
              "        2.7381628 , -1.4414704 ,  1.9006734 ,  0.13591126,  1.1135874 ,\n",
              "       -0.5841767 , -2.1699212 , -0.74955994,  1.3712415 , -1.2692451 ,\n",
              "        2.9015708 , -0.46379066,  1.2144006 , -1.7756954 , -2.5923414 ,\n",
              "       -0.12859172, -1.050146  , -2.5589857 , -0.4764793 ,  0.5757201 ,\n",
              "        2.653173  , -1.0175519 ,  1.3231046 , -0.6623386 , -2.3848255 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWdfqY5QuPRa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.wv."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CItdPnnHGk66",
        "colab_type": "text"
      },
      "source": [
        "## Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MMsUOIp-fNX",
        "colab_type": "code",
        "outputId": "c044b18f-5de9-42cd-b27d-26053a3d09fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "model.save(\"word2vec movie-50\")                                                    # We save this model for further use.\n",
        "                                                                                   # Google has such many pre-trained models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 08:46:57,134 : INFO : saving Word2Vec object under word2vec movie-50, separately None\n",
            "2018-08-07 08:46:57,136 : INFO : not storing attribute vectors_norm\n",
            "2018-08-07 08:46:57,138 : INFO : not storing attribute cum_table\n",
            "2018-08-07 08:46:57,356 : INFO : saved word2vec movie-50\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a1G2kw_6kf2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GUgohwEuWlY",
        "colab_type": "text"
      },
      "source": [
        "# Sentiment Analysis with pre-trained Word2Vec model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAQXgw03nEXb",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "In this tutorial we'll do Sentiment analysis based on the concept of Word2Vec using our **pre-trained model** with unlabelled data where we've applied **Word2Vec** technique i.e representing a word with a dense vector of **50 numbers**. The unlabelled data has **50000 IMDB movie reviews** & we extracted  some **28000+** unique words after doing some data preprocessing & applying Word2Vec technique with length of 50 numbers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9hFkqqmnKqC",
        "colab_type": "text"
      },
      "source": [
        "###Set the seed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXb44GXhnSkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91e2PZR_nX-l",
        "colab_type": "text"
      },
      "source": [
        "###Load data\n",
        "Data can be downloaded from Kaggle -> https://www.kaggle.com/c/word2vec-nlp-tutorial/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov9QKZFTnTUu",
        "colab_type": "code",
        "outputId": "9980ca75-c3b3-4a4f-cb76-35226b0c155f",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c64d72a-275d-42a4-b5f7-7181ada93ace\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-8c64d72a-275d-42a4-b5f7-7181ada93ace\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving labeledTrainData.tsv to labeledTrainData.tsv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T21NoUqcnald",
        "colab_type": "code",
        "outputId": "551e7ec5-77f2-4970-a46c-5923081c4475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('labeledTrainData.tsv',  #filepath\n",
        "                 header=0, delimiter=\"\\t\", quoting=3)\n",
        "\n",
        "print(df1.shape)  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zP7Bh8CXnq8d",
        "colab_type": "text"
      },
      "source": [
        "## About the data\n",
        "\n",
        "The labelled data set contains 25000 reviews with label(**Sentiment**). The output column  Sentiment consists of 2 categories[0 & 1]. \n",
        "\n",
        "**0 -- Indicates negative sentiment **               ,  if the rating < 5\n",
        "\n",
        "**1-- Indicates positive sentiment **                  , if the rating >= 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "537_Pz8Rnaoy",
        "colab_type": "code",
        "outputId": "78fcf3e1-ba6d-4d13-9199-3cb4d6504c5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df1.iloc[10:15,:]                                                                  # Have 10th & 11th review of the dataset alongwith review id, sentiment."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>\"11744_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>\"7369_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"I had a feeling that after \\\"Submerged\\\", thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>\"12081_1\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"note to George Litman, and others: the Myster...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli...\n",
              "12  \"11744_9\"          1  \"\\\"Mr. Harvey Lights a Candle\\\" is anchored by...\n",
              "13   \"7369_1\"          0  \"I had a feeling that after \\\"Submerged\\\", thi...\n",
              "14  \"12081_1\"          0  \"note to George Litman, and others: the Myster..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DA0WOP_Mn0s0",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyBpzQpIn6i9",
        "colab_type": "text"
      },
      "source": [
        "**1.Split Data into Training and Test Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UipXytQsnary",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df1['review'],\n",
        "    df1['sentiment'],\n",
        "    test_size=0.2, \n",
        "    random_state=42\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GaoXClWoCYz",
        "colab_type": "text"
      },
      "source": [
        "**2.Build Tokenizer to get Number sequences for Each review**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5cQEWFenaut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Vocab size\n",
        "top_words = 10000\n",
        "\n",
        "t = Tokenizer(num_words=top_words)\n",
        "t.fit_on_texts(X_train.tolist())\n",
        "\n",
        "#Get the word index for each of the word in the review\n",
        "X_train = t.texts_to_sequences(X_train.tolist())\n",
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOEpL98doNTN",
        "colab_type": "text"
      },
      "source": [
        "**3.Pad sequences to make each review size equal Get the word index for each of the word in the review**\n",
        "\n",
        "We  want to bring all the reviewa into same length because we want to build matrix with this dimension"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqXkimj3oXTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.preprocessing import sequence\n",
        "\n",
        "#Each review size\n",
        "max_review_length = 300\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train,maxlen=max_review_length,padding='post')\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length, padding='post') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoZCpIZeoc34",
        "colab_type": "text"
      },
      "source": [
        "## Build Embedding Matrix from Pre-Trained Word2Vec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5xftICooe2Z",
        "colab_type": "code",
        "outputId": "5b53fdc7-97f5-44d5-8e12-56ee4ba638d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "#Install gensim\n",
        "!pip install gensim --quiet\n",
        "\n",
        "#Load pre-trained model\n",
        "import gensim\n",
        "word2vec = gensim.models.Word2Vec.load('word2vec movie-50')\n",
        "\n",
        "#Embedding Length\n",
        "embedding_vector_length = word2vec.wv.vectors.shape[1]\n",
        "\n",
        "print('Loaded word2vec model..')\n",
        "print('Model shape: ', word2vec.wv.vectors.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-08-07 10:03:28,370 : INFO : loading Word2Vec object from word2vec movie-50\n",
            "2018-08-07 10:03:28,543 : INFO : loading wv recursively from word2vec movie-50.wv.* with mmap=None\n",
            "2018-08-07 10:03:28,544 : INFO : setting ignored attribute vectors_norm to None\n",
            "2018-08-07 10:03:28,545 : INFO : loading vocabulary recursively from word2vec movie-50.vocabulary.* with mmap=None\n",
            "2018-08-07 10:03:28,552 : INFO : loading trainables recursively from word2vec movie-50.trainables.* with mmap=None\n",
            "2018-08-07 10:03:28,554 : INFO : setting ignored attribute cum_table to None\n",
            "2018-08-07 10:03:28,557 : INFO : loaded word2vec movie-50\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded word2vec model..\n",
            "Model shape:  (28322, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvXA1a5Zop5M",
        "colab_type": "code",
        "outputId": "0e1d9e6d-bf47-4444-ff7e-b325fc2d41e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "word2vec.wv.vector_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxuznkdnowdn",
        "colab_type": "text"
      },
      "source": [
        "**Build matrix for current data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5zL8xsAop-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize embedding matrix to all zeros\n",
        "embedding_matrix = np.zeros((top_words + 1, # Vocablury size + 1,, we add 1 to vocab size for padding\n",
        "                             embedding_vector_length))\n",
        "\n",
        "#Steps for populating embedding matrix\n",
        "\n",
        "#1. Check each word in tokenizer vocablury to see if it exist in pre-trained\n",
        "# word2vec model.\n",
        "#2. If found, update embedding matrix with embeddings for the word \n",
        "# from word2vec model\n",
        "\n",
        "for word, i in sorted(t.word_index.items(),key=lambda x:x[1]):\n",
        "    if i > top_words:\n",
        "        break\n",
        "    if word in word2vec.wv.vocab:\n",
        "        embedding_vector = word2vec.wv[word]\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZzFuBkzoqBA",
        "colab_type": "code",
        "outputId": "6dbc86c5-bbc8-4e75-9aaa-fc89995385ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Check embeddings for word 'great'\n",
        "embedding_matrix[t.word_index['great']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.59144205,  0.94809264,  2.92205071, -2.57998848,  2.06668258,\n",
              "        0.03379907, -2.07701755, -1.28192663,  2.37326407, -1.6968323 ,\n",
              "       -1.46692789, -2.43406081, -0.99238962, -2.35702658,  0.37269598,\n",
              "       -1.23948109,  1.67976511,  1.22183132, -2.27092576, -0.52730691,\n",
              "        2.21310592,  3.8952992 , -1.38157284, -0.99453694, -0.90861291,\n",
              "       -1.57382619, -0.62930226,  1.70807695, -1.20810831,  2.12286615,\n",
              "       -0.50363177, -0.57258892, -0.01908715, -2.85462713,  0.36451188,\n",
              "        0.2708773 ,  3.52137017,  2.90140653,  2.48585653, -2.98677659,\n",
              "       -1.01710439,  1.52898908, -0.93782079,  0.80436903, -3.12551713,\n",
              "        1.43007016,  2.68136525,  1.97543514,  0.14813299,  2.30020237])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjgKk9JprPvc",
        "colab_type": "text"
      },
      "source": [
        "## Build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6oNRfbcoqDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dropout, Dense, Embedding, Flatten\n",
        "\n",
        "#Build a sequential model\n",
        "model1 = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpXa42e0rYoc",
        "colab_type": "text"
      },
      "source": [
        "**Add Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9FUNpgeoqGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.add(Embedding(top_words + 1,\n",
        "                    embedding_vector_length,\n",
        "                    input_length=max_review_length,\n",
        "                    weights=[embedding_matrix],                                    # Pre-trained embedding\n",
        "                    trainable=False)                                               # We do not want to change embedding\n",
        "         )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFsjGhSXrw7b",
        "colab_type": "text"
      },
      "source": [
        "Output from Embedding is 3 dimension \n",
        "- batch_size x max_review_length x embedding_vector_length. \n",
        "\n",
        "We need to flatten the output for Dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esaAPDRioqLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Flatten embedding layer output and flatten layers\n",
        "model1.add(Flatten())                                                             # Flatten enables us to bring down the dimension of the prepared data\n",
        "model1.add(Dense(200,activation='relu'))                                          # Dense layer is for fully connected layer\n",
        "model1.add(Dense(100,activation='relu'))\n",
        "model1.add(Dropout(0.5))                                                          # Dropout is required to avoid overfiting & make the model generalize\n",
        "model1.add(Dense(60,activation='relu'))\n",
        "model1.add(Dropout(0.4))\n",
        "model1.add(Dense(30,activation='relu'))\n",
        "model1.add(Dropout(0.3))\n",
        "model1.add(Dense(1,activation='sigmoid'))                                         # We've used sigmoid because output variable is binary\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3KyXjkXxdxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from keras.utils import to_categorical\n",
        "#Y_train=to_categorical(y_train,2)\n",
        "#Y_test=to_categorical(y_test,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xH1o_Swr98W",
        "colab_type": "text"
      },
      "source": [
        "## Execute the graph\n",
        "\n",
        "Here we'll  use split data to find train & validation accuracy with 10 iterations on 20000 train data & 5000 validation data with batch size of 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n56qw2p1oqJo",
        "colab_type": "code",
        "outputId": "653956e2-bac7-4edb-fc02-3b186c31af54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "model1.fit(X_train,y_train,\n",
        "          epochs=5,\n",
        "          batch_size=200,          \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 11s 568us/step - loss: 0.7227 - acc: 0.5473 - val_loss: 0.6284 - val_acc: 0.6926\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 10s 488us/step - loss: 0.5602 - acc: 0.7196 - val_loss: 0.5279 - val_acc: 0.7364\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 10s 491us/step - loss: 0.4260 - acc: 0.8138 - val_loss: 0.5049 - val_acc: 0.7600\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 10s 490us/step - loss: 0.3235 - acc: 0.8696 - val_loss: 0.5206 - val_acc: 0.7528\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 10s 490us/step - loss: 0.2279 - acc: 0.9125 - val_loss: 0.6552 - val_acc: 0.7508\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0962e4ff60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnFqC8IosK_m",
        "colab_type": "code",
        "outputId": "ab93ec1d-6c73-4a5a-939d-e116976ced23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model1.predict(X_test[10:12])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.91270083],\n",
              "       [0.04830996]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA_yd1JcxUvh",
        "colab_type": "code",
        "outputId": "ebf03d94-e0fd-48dc-cab0-661a55e4629d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "df1.iloc[10:12,:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>\"2486_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"What happens when an army of wetbacks, towelh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>\"6811_10\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Although I generally do not like remakes beli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  sentiment                                             review\n",
              "10   \"2486_3\"          0  \"What happens when an army of wetbacks, towelh...\n",
              "11  \"6811_10\"          1  \"Although I generally do not like remakes beli..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAVyObUcLqV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}