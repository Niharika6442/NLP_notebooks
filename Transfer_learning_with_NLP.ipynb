{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_learning_with_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idEyIgYm0vPY",
        "colab_type": "text"
      },
      "source": [
        "# Transfer learning using Universal Sentence Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJH1sjyl0od3",
        "colab_type": "text"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wFyj25qUiMd",
        "colab_type": "code",
        "outputId": "998654e9-924e-4726-d6f8-a86ecd8dd1cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "np.random.seed(10)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPfAFCyY04C5",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V1J1P5NUlOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X97nqrJYUpIi",
        "colab_type": "code",
        "outputId": "169a1478-bebe-4ed0-b004-1a9d9cc7761b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# Import the Universal Sentence Encoder's TF Hub module\n",
        "embed = hub.Module(module_url)\n",
        "\n",
        "# Compute a representation for each message, showing various lengths supported.\n",
        "word = \"Elephant\"\n",
        "sentence = \"I am a sentence for which I would like to get its embedding.\"\n",
        "paragraph = (\n",
        "    \"Universal Sentence Encoder embeddings also support short paragraphs. \"\n",
        "    \"There is no hard limit on how long the paragraph is. Roughly, the longer \"\n",
        "    \"the more 'diluted' the embedding will be.\")\n",
        "messages = [word, sentence, paragraph]\n",
        "\n",
        "# Reduce logging output.\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "with tf.Session() as session:\n",
        "  session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "  message_embeddings = session.run(embed(messages))\n",
        "\n",
        "  for i, message_embedding in enumerate(np.array(message_embeddings).tolist()):\n",
        "    print(\"Message: {}\".format(messages[i]))\n",
        "    print(\"Embedding size: {}\".format(len(message_embedding)))\n",
        "    message_embedding_snippet = \", \".join(\n",
        "        (str(x) for x in message_embedding[:3]))\n",
        "    print(\"Embedding: [{}, ...]\\n\".format(message_embedding_snippet))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message: Elephant\n",
            "Embedding size: 512\n",
            "Embedding: [0.04498475790023804, -0.057433921843767166, 0.002211492508649826, ...]\n",
            "\n",
            "Message: I am a sentence for which I would like to get its embedding.\n",
            "Embedding size: 512\n",
            "Embedding: [0.055680178105831146, -0.00960793811827898, 0.00624628784134984, ...]\n",
            "\n",
            "Message: Universal Sentence Encoder embeddings also support short paragraphs. There is no hard limit on how long the paragraph is. Roughly, the longer the more 'diluted' the embedding will be.\n",
            "Embedding size: 512\n",
            "Embedding: [0.03874940052628517, 0.0765201598405838, -0.0007945735123939812, ...]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBTwOs4JVDRt",
        "colab_type": "code",
        "outputId": "b602339b-3e0b-4aed-86fa-ed2a259f2146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#size of embedding\n",
        "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
        "embed_size\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpdFlvTM2jis",
        "colab_type": "text"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py5FUAQtVpwE",
        "colab_type": "code",
        "outputId": "67af8870-9cda-439e-f2a8-1b6c56d6ce02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/train_5500.txt\n",
        "!wget https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/test_data.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-11 11:24:03--  https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/train_5500.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 335860 (328K) [text/plain]\n",
            "Saving to: ‘train_5500.txt’\n",
            "\n",
            "\rtrain_5500.txt        0%[                    ]       0  --.-KB/s               \rtrain_5500.txt      100%[===================>] 327.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-11-11 11:24:03 (6.26 MB/s) - ‘train_5500.txt’ saved [335860/335860]\n",
            "\n",
            "--2019-11-11 11:24:05--  https://raw.githubusercontent.com/Tony607/Keras-Text-Transfer-Learning/master/test_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23354 (23K) [text/plain]\n",
            "Saving to: ‘test_data.txt’\n",
            "\n",
            "test_data.txt       100%[===================>]  22.81K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-11-11 11:24:05 (1.80 MB/s) - ‘test_data.txt’ saved [23354/23354]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B2eIRUj3X-3",
        "colab_type": "text"
      },
      "source": [
        "## Decscription of Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXpR6dEE3a6r",
        "colab_type": "text"
      },
      "source": [
        "The dataset we use is the TREC Question Classification dataset, There are entirely 5452 training and 500 test samples, that is 5452 + 500 questions each categorized into one of the six labels.\n",
        "\n",
        "- ABBR - 'abbreviation': expression abbreviated, etc.\n",
        "- DESC - 'description and abstract concepts': manner of an action, description of sth. etc.\n",
        "- ENTY - 'entities': animals, colors, events, food, etc.\n",
        "- HUM - 'human beings': a group or organization of persons, an individual, etc.\n",
        "- LOC - 'locations': cities, countries, etc.\n",
        "- NUM - 'numeric values': postcodes, dates, speed,temperature, etc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6NTBzTaV3a9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract lines from .txt and convert to dataframe\n",
        "\n",
        "def get_dataframe(filename):\n",
        "    lines = open(filename, 'r').read().splitlines()\n",
        "    data = []\n",
        "    for i in range(0, len(lines)):\n",
        "        label = lines[i].split(' ')[0]\n",
        "        label = label.split(\":\")[0]\n",
        "        text = ' '.join(lines[i].split(' ')[1:])\n",
        "        text = re.sub('[^A-Za-z0-9 ,\\?\\'\\\"-._\\+\\!/\\`@=;:]+', '', text)\n",
        "        data.append([label, text])\n",
        "\n",
        "    df = pd.DataFrame(data, columns=['label', 'text'])\n",
        "    df.label = df.label.astype('category')\n",
        "    return df\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KFQSdpSWEB7",
        "colab_type": "code",
        "outputId": "8375fe52-e2a8-4429-b554-cb88c4e22570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "#Assign train data\n",
        "df_train = get_dataframe('train_5500.txt')\n",
        "print(df_train.head())\n",
        "df_test = get_dataframe('test_data.txt')\n",
        "print(df_test.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  label                                               text\n",
            "0  DESC  How did serfdom develop in and then leave Russ...\n",
            "1  ENTY   What films featured the character Popeye Doyle ?\n",
            "2  DESC  How can I find a list of celebrities ' real na...\n",
            "3  ENTY  What fowl grabs the spotlight after the Chines...\n",
            "4  ABBR                    What is the full form of .com ?\n",
            "  label                                      text\n",
            "0   NUM      How far is it from Denver to Aspen ?\n",
            "1   LOC  What county is Modesto , California in ?\n",
            "2   HUM                         Who was Galileo ?\n",
            "3  DESC                         What is an atom ?\n",
            "4   NUM          When did Hawaii become a state ?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTwA-WJbWIC0",
        "colab_type": "code",
        "outputId": "93443fe0-4638-46ad-d623-04b7c28f8bb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Number of categories in dataset\n",
        "category_counts = len(df_train.label.cat.categories)\n",
        "category_counts"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XRwKqA4WK_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert input into strings  \n",
        "def UniversalEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_haacVQ4w7d",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdB8p4yTWe6O",
        "colab_type": "code",
        "outputId": "416a488c-6d6d-420b-c4e7-6736d54f23ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
        "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
        "dense = layers.Dense(256, activation='relu')(embedding)\n",
        "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 1542      \n",
            "=================================================================\n",
            "Total params: 132,870\n",
            "Trainable params: 132,870\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQsOxK7WhQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert train text to  an array and labels as get_dummies\n",
        "train_text = df_train['text'].tolist()\n",
        "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
        "train_label = np.asarray(pd.get_dummies(df_train.label), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-CLztDgWmlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = get_dataframe('test_data.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a_PGMR0Wrmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert test text to  an array and labels as get_dummies\n",
        "test_text = df_test['text'].tolist()\n",
        "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
        "test_label = np.asarray(pd.get_dummies(df_test.label), dtype = np.int8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0xAbnzt6cZW",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EjRgmhrWtqF",
        "colab_type": "code",
        "outputId": "376d5bc4-5992-4078-e597-9d85b4efa983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  history = model.fit(train_text, \n",
        "            train_label,\n",
        "            validation_data=(test_text, test_label),\n",
        "            epochs=10,\n",
        "            batch_size=32)\n",
        "  model.save_weights('./model.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5452 samples, validate on 500 samples\n",
            "Epoch 1/10\n",
            "5452/5452 [==============================] - 69s 13ms/step - loss: 0.7248 - acc: 0.8118 - val_loss: 0.3012 - val_acc: 0.9160\n",
            "Epoch 2/10\n",
            "5452/5452 [==============================] - 67s 12ms/step - loss: 0.3228 - acc: 0.8958 - val_loss: 0.2413 - val_acc: 0.9220\n",
            "Epoch 3/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2801 - acc: 0.9017 - val_loss: 0.2212 - val_acc: 0.9340\n",
            "Epoch 4/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2600 - acc: 0.9103 - val_loss: 0.2181 - val_acc: 0.9300\n",
            "Epoch 5/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2461 - acc: 0.9145 - val_loss: 0.2102 - val_acc: 0.9380\n",
            "Epoch 6/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2330 - acc: 0.9228 - val_loss: 0.2281 - val_acc: 0.9260\n",
            "Epoch 7/10\n",
            "5452/5452 [==============================] - 67s 12ms/step - loss: 0.2211 - acc: 0.9263 - val_loss: 0.2017 - val_acc: 0.9360\n",
            "Epoch 8/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2116 - acc: 0.9274 - val_loss: 0.2083 - val_acc: 0.9340\n",
            "Epoch 9/10\n",
            "5452/5452 [==============================] - 66s 12ms/step - loss: 0.2026 - acc: 0.9309 - val_loss: 0.2134 - val_acc: 0.9340\n",
            "Epoch 10/10\n",
            "5452/5452 [==============================] - 65s 12ms/step - loss: 0.1919 - acc: 0.9353 - val_loss: 0.1997 - val_acc: 0.9380\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw3ZiaqR6gSl",
        "colab_type": "text"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adGmjbgDW2iS",
        "colab_type": "code",
        "outputId": "306ced65-9d4a-46ba-e685-ff8a150cdf02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "new_text = [\"In what year did the titanic sink ?\", \n",
        "            \"What is the highest peak in California ?\", \n",
        "            \"Who invented the light bulb ?\"]\n",
        "\n",
        "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
        "with tf.Session() as session:\n",
        "  K.set_session(session)\n",
        "  session.run(tf.global_variables_initializer())\n",
        "  session.run(tf.tables_initializer())\n",
        "  model.load_weights('./model.h5')  \n",
        "  predicts = model.predict(new_text, batch_size=32)\n",
        "\n",
        "categories = df_train.label.cat.categories.tolist()\n",
        "predict_logits = predicts.argmax(axis=1)\n",
        "predict_labels = [categories[logit] for logit in predict_logits]\n",
        "print(predict_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['NUM', 'LOC', 'HUM']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXyQuJGPPNvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}